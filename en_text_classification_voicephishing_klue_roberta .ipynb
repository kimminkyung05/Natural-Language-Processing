{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZDc66de1mEm"
      },
      "source": [
        "*ì´íƒ¤ë¦­ì²´ í…ìŠ¤íŠ¸*# ğŸ‡ºHugging Face Transformers Text Classification Tutorial (Colab)\n",
        "\n",
        "*Created on: 2025-09-06 11:35:23*\n",
        "\n",
        "This notebook is designed to run smoothly on Google Colab (T4).\n",
        "\n",
        "## Learning Objectives\n",
        "1. ğŸ¤— Load a binary voice-phishing dataset using Hugging Face Datasets\n",
        "2. ğŸ§  Fine-tune a Korean text classification model using `klue/roberta-small`\n",
        "3. ğŸ§© Understand how to use `AutoModelForSequenceClassification`, `TrainingArguments`, and `Trainer`\n",
        "4. ğŸ§° Inspect the Tokenizer and `DataCollatorWithPadding`\n",
        "5. ğŸ“Š Evaluate (Accuracy/F1) after training and practice making predictions\n",
        "\n",
        "## Resources\n",
        "- **Model**: `klue/roberta-small`\n",
        "- **Dataset**: `HyaDoo/ko-voicephishing-binary-classification` (text â†’ binary classification for voice phishing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAoXXITXV9mf"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uTlmrcv1mEn"
      },
      "source": [
        "## 0. Check runtime environment & install required packages\n",
        "Install the basic packages to run quickly in a Colab T4 environment.\n",
        "\n",
        "(If running locally, you can skip GPU-specific checks.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2YivAFa170n"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi -L || true\n",
        "!python -V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJzpK0HA7BIP"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -q transformers datasets accelerate evaluate scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFImyAlG1mEo"
      },
      "source": [
        "## 1. Import libraries & set random seed\n",
        "\n",
        "Import required libraries and fix random seeds for reproducible training runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJFJ4VQE1mEo"
      },
      "outputs": [],
      "source": [
        "import os, random, numpy as np, torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import DataCollatorWithPadding, TrainingArguments, Trainer\n",
        "import evaluate\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FNzhNj91mEp"
      },
      "source": [
        "## 2. Dataset loading and structure check\n",
        "- Dataset: **`HyaDoo/ko-voicephishing-binary-classification`**\n",
        "- Main field: `text` (ASR output text) â†’ label (voice-phishing or not)\n",
        "\n",
        "Split names (train/validation/test) may differ by dataset; the code below robustly handles various cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_20HgIU51mEp"
      },
      "outputs": [],
      "source": [
        "dataset_name = 'HyaDoo/ko-voicephishing-binary-classification'\n",
        "raw = load_dataset(dataset_name)\n",
        "raw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOlATeye1mEp"
      },
      "source": [
        "### 2-1. Normalize splits (create if missing) & detect label column\n",
        "Some public datasets use different label field names like `label`/`labels`/`target`. The utility below auto-detects the label column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fO5IvKZV1mEp"
      },
      "outputs": [],
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "def pick_label_column(example_keys):\n",
        "    candidates = ['label', 'labels', 'target', 'y']\n",
        "    for c in candidates:\n",
        "        if c in example_keys:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "# Normalize splits:\n",
        "# - If the dataset only contains a single 'train' split, create train/test split (80/20) and name the test split 'test'.\n",
        "# - If 'train' exists alongside 'validation' or 'test', keep as-is.\n",
        "# - If no 'train' split exists, split the first available split into train/test.\n",
        "split_names = list(raw.keys())\n",
        "if 'train' in raw and len(split_names) == 1:\n",
        "    print(\"Dataset contains only 'train' split: creating train/test split (80/20). Using 'test' as the evaluation split.\")\n",
        "    tmp = raw['train'].train_test_split(test_size=0.2, seed=seed)\n",
        "    ds = DatasetDict({'train': tmp['train'], 'test': tmp['test']})\n",
        "elif 'train' in raw:\n",
        "    # Dataset already has train (and possibly validation/test)\n",
        "    # Prefer keeping 'test' if it exists; otherwise keep any existing 'validation' as-is but ensure we have a 'test' key for consistency.\n",
        "    ds = raw\n",
        "    if 'test' not in ds and 'validation' in ds:\n",
        "        # keep existing 'validation' but also make it available under 'test'\n",
        "        ds['test'] = ds['validation']\n",
        "else:\n",
        "    # No explicit 'train' split: split the first available split into train/test\n",
        "    first_split_name = split_names[0]\n",
        "    tmp = raw[first_split_name].train_test_split(test_size=0.2, seed=seed)\n",
        "    ds = DatasetDict({'train': tmp['train'], 'test': tmp['test']})\n",
        "\n",
        "sample_keys = ds['train'].column_names\n",
        "label_col = pick_label_column(sample_keys)\n",
        "text_col = 'text' if 'text' in sample_keys else sample_keys[0]\n",
        "label_col, text_col, sample_keys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeQs8Jnc1mEq"
      },
      "source": [
        "### 2-2. Preview data & label distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVXuz3Bo1mEq"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "print(\"Train sample:\")\n",
        "print(ds['train'][0])\n",
        "\n",
        "if label_col is not None:\n",
        "    train_labels = [ex[label_col] for ex in ds['train']]\n",
        "    print(\"\\nLabel distribution (train):\", Counter(train_labels))\n",
        "else:\n",
        "    print(\"[WARNING] Could not detect a label column. Subsequent preprocessing steps may fail.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7U9HDM01mEq"
      },
      "source": [
        "## 3. Tokenizer & tokenization\n",
        "- Model/Tokenizer: `klue/roberta-small`\n",
        "- Recommended max_length for Colab T4: 128â€“256 (using 256 here)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWSFbvFv1mEq"
      },
      "outputs": [],
      "source": [
        "model_name = \"klue/roberta-small\"   #ì´ ë¶€ë¶„ì„ small ,base, large ëª¨ë¸ë¡œ ë°”ê¿ˆ\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "max_length = 128\n",
        "def tokenize_fn(batch):\n",
        "    return tokenizer(batch[text_col], truncation=True, max_length=max_length)\n",
        "\n",
        "tokenized = ds.map(\n",
        "    tokenize_fn,\n",
        "    batched=True,\n",
        "    remove_columns=[c for c in ds[\"train\"].column_names if c not in [text_col, label_col]]\n",
        ")\n",
        "\n",
        "print(tokenized)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-iH0fpi_SG2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnEB4HCJ1mEq"
      },
      "source": [
        "## 4. DataCollatorWithPadding\n",
        "Use a data collator that automatically pads variable-length batches.\n",
        "ëª‡ ê°€ì§€ ë°ì´í„°ì½œë ˆì´í„°ê°€ ì¡´ì¬ ì˜ˆë¥¼ ë“¤ì–´ í…ìŠ¤íŠ¸í´ë˜ì‹œí”¼ì¼€ì´ì…˜\n",
        "ìµœì¢…ì ìœ¼ë¡œ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°ˆ ë•ŒëŠ” í…ì„œê°€ ë“¤ì–´ê°€ì•¼í•˜ëŠ”ë° í…ì„œë¡œ ë°”ê¾¸ëŠ” ë§ˆì§€ë§‰ ì²˜ë¦¬(ëª¨ë¸ë¡œ ë“¤ì–´ê°€ê¸° ì „ì—) + íŒ¨ë”© ì²˜ë¦¬ë¥¼ ì‹œí–‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iStTQFtv1mEq"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "data_collator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwDjrpZJ1mEq"
      },
      "source": [
        "## 5. Model loading (AutoModelForSequenceClassification)\n",
        "- Set `num_labels=2` for binary classification\n",
        "- CUDA will be used automatically if a GPU is available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vt2Z_1tO1mEq"
      },
      "outputs": [],
      "source": [
        "num_labels = 2\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels\n",
        ").to(device)\n",
        "model.config.id2label = {0: 'non_phishing', 1: 'phishing'}\n",
        "model.config.label2id = {'non_phishing': 0, 'phishing': 1}\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKalZn_o1mEr"
      },
      "source": [
        "## 6. Define evaluation metrics\n",
        "- Use `evaluate` and `scikit-learn` to compute Accuracy, Precision, Recall, and F1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRZz9tPD1mEr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "accuracy = evaluate.load('accuracy')\n",
        "precision = evaluate.load('precision')\n",
        "recall = evaluate.load('recall')\n",
        "f1 = evaluate.load('f1')\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        'accuracy': accuracy.compute(references=labels, predictions=preds)['accuracy'],\n",
        "        'precision': precision.compute(references=labels, predictions=preds, average='binary')['precision'],\n",
        "        'recall': recall.compute(references=labels, predictions=preds, average='binary')['recall'],\n",
        "        'f1': f1.compute(references=labels, predictions=preds, average='binary')['f1'],\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZcJZ1xiZWyj"
      },
      "source": [
        "í›ˆë ¨ì„ ì‹œí‚¬ ì‹œ íŠ¸ë ˆì´ë‹ í•  ë•Œ computer metrixë¥¼ êµ¬í˜„.. ì‹¸ì´í‚·ëŸ°(ppt ì˜ˆì‹œ) ë§ê³  ìì²´ ëª¨ë¸ì„ ì‚¬ìš©í•¨. ê´€ë ¨ ì½”ë“œë¥¼ í—ˆë¸Œì—ì„œ ë‚´ë ¤ë°›ìŒ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWTijmz91mEr"
      },
      "source": [
        "## 7. TrainingArguments\n",
        "- Configure batch size and epochs suitable for Colab T4 (adjust as needed)\n",
        "- Use FP16 for speed and memory optimization\n",
        "- Set checkpoint/logging/evaluation frequencies\n",
        "\n",
        "ì–´ë””ì— ì²´í¬ í¬ì¸íŠ¸ë¥¼ ì €ì¥í• ê±´ê°€\n",
        "ê°€ì¥ ì¢‹ì€ ëª¨ë¸ì„ saveí•´ì„œ ì €ì¥ í‰ê°€ëŠ” metrix f1ìœ¼ë¡œ ê¸°ì¤€ì„ ì¡ê³  evaluationì´ í° ê°’ì„ ì´ìš©í• ê²…"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LXxBakvA1mEr"
      },
      "outputs": [],
      "source": [
        "output_dir = 'outputs-roberta-voicephishing'\n",
        "args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='f1',\n",
        "    greater_is_better=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=['none'],\n",
        "    seed=seed,\n",
        ")\n",
        "args"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGyl8WhC1mEr"
      },
      "source": [
        "## 8. Create Trainer and run training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEEPPYGo1mEr"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized['train'],\n",
        "    eval_dataset=tokenized.get('test', tokenized['train'].select(range(100))),\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsumcUUp1mEr"
      },
      "source": [
        "## 9. Evaluation and prediction testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZ1k-OEY1mEr"
      },
      "outputs": [],
      "source": [
        "metrics = trainer.evaluate()\n",
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKLEmxmT1mEr"
      },
      "outputs": [],
      "source": [
        "def predict_texts(texts):\n",
        "    # Use the trained model object directly\n",
        "    enc = tokenizer(texts, truncation=True, max_length=max_length, return_tensors='pt', padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**enc)\n",
        "        # Access the logits from the first element of the tuple output\n",
        "        logits = outputs[0] #ê°€ì¥ í° ê°’ì´ ë‚˜ì˜´\n",
        "    preds = torch.argmax(logits, dim=-1).cpu().numpy().tolist()\n",
        "    probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
        "    mapped = [model.config.id2label[p] for p in preds]\n",
        "    return list(zip(texts, mapped, probs.tolist()))\n",
        "\n",
        "samples = [\n",
        "    \"ê³ ê°ë‹˜ ëŒ€ì¶œ í•œë„ ìƒí–¥ë˜ì–´ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤. ëŒ€ì¶œ ì‹¤í–‰ì„ ìœ„í•´ ë³¸ì¸ì¸ì¦ í•„ìš”í•©ë‹ˆë‹¤.\",\n",
        "    \"ì•ˆë…•í•˜ì„¸ìš”, ë‚´ì¼ ì˜¤í›„ 3ì‹œì— ë¯¸íŒ… ê°€ëŠ¥í•˜ì‹ ê°€ìš”?\",\n",
        "]\n",
        "predict_texts(samples) #í™•ë¥  ê°’ê¹Œì§€ ì¶œë ¥ ê°€ëŠ¥"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atfg3kRh1mEr"
      },
      "source": [
        "## 10. Model saving and loading\n",
        "Show how to save the trained weights and tokenizer to disk and reload them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RM0Xj8SM1mEr"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "SIZE = \"small\"  # small / base / large ì¤‘ ì„ íƒ\n",
        "save_dir = f\"saved-roberta-{SIZE}-voicephishing\"\n",
        "\n",
        "trainer.save_model(save_dir)\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "trainer.model.config.save_pretrained(save_dir)\n",
        "\n",
        "print('Saved to', save_dir)\n",
        "reloaded = AutoModelForSequenceClassification.from_pretrained(\n",
        "    save_dir, local_files_only=True\n",
        ").to(device)\n",
        "reloaded\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm2uJJK51mEr"
      },
      "source": [
        "## 11. (Optional) Confusion matrix & classification report\n",
        "Print a simple performance report on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpp-5epr1mEr"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Use the 'test' split for evaluation/reporting\n",
        "eval_ds = tokenized.get('test', tokenized['train'].select(range(200)))\n",
        "pred = trainer.predict(eval_ds)\n",
        "y_true = pred.label_ids\n",
        "y_pred = pred.predictions.argmax(axis=-1)\n",
        "print(classification_report(y_true, y_pred, target_names=['non_phishing','phishing']))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgOkrBH51mEs"
      },
      "source": [
        "## Tips\n",
        "- Adjust batch size / epochs / learning rate according to Colab session and dataset size.\n",
        "- If training is slow, reduce `max_length` to 128 or lower the batch size.\n",
        "- `report_to=['none']` disables external logging like WandB.\n",
        "- Public datasets can be loaded without local tokens.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJNDgsP07yq0"
      },
      "source": [
        "## 12. TODO\n",
        "\n",
        "\n",
        "- Write code that loads the model trained with a pipeline, takes a sentence as input, and immediately checks the classification result.\n",
        "- Replace the model with klue/roberta-base and klue/roberta-large, run them, and investigate how each of these models differs from klue/roberta-small."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIVhPvTcIUft"
      },
      "source": [
        "#13. TODO- homework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYPDXH1kdIc4"
      },
      "outputs": [],
      "source": [
        "# pip install -U transformers torch accelerate\n",
        "import os, time, torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "\n",
        "ID2LABEL = {0: \"non_phishing\", 1: \"phishing\"}\n",
        "LABEL2ID = {\"non_phishing\": 0, \"phishing\": 1}\n",
        "MAX_LEN  = 128\n",
        "POSTPROC = \"softmax\"\n",
        "THRESH   = 0.5\n",
        "\n",
        "SAVE_DIRS = {\n",
        "    \"klue/roberta-small\": \"saved-roberta-small-voicephishing\",\n",
        "    \"klue/roberta-base\":  \"saved-roberta-base-voicephishing\",\n",
        "    \"klue/roberta-large\": \"saved-roberta-large-voicephishing\",\n",
        "}\n",
        "\n",
        "def _is_local_model_dir(path: str) -> bool:\n",
        "    return os.path.isdir(path) and os.path.isfile(os.path.join(path, \"config.json\"))\n",
        "\n",
        "def _ensure_label_maps_saved(dirpath: str):\n",
        "    m = AutoModelForSequenceClassification.from_pretrained(dirpath, local_files_only=True)\n",
        "    need = False\n",
        "    if not isinstance(getattr(m.config, \"id2label\", None), dict) or len(m.config.id2label) != m.config.num_labels:\n",
        "        m.config.id2label = ID2LABEL; need = True\n",
        "    if not isinstance(getattr(m.config, \"label2id\", None), dict) or set(m.config.label2id.keys()) != set(LABEL2ID.keys()):\n",
        "        m.config.label2id = LABEL2ID; need = True\n",
        "    if need:\n",
        "        m.config.save_pretrained(dirpath)\n",
        "    return need\n",
        "\n",
        "def _build_pipeline_local(dirpath: str):\n",
        "    tok = AutoTokenizer.from_pretrained(dirpath, local_files_only=True)\n",
        "    mdl = AutoModelForSequenceClassification.from_pretrained(dirpath, local_files_only=True)\n",
        "\n",
        "    mdl.config.return_dict = True\n",
        "    mdl.config.id2label = getattr(mdl.config, \"id2label\", ID2LABEL) or ID2LABEL\n",
        "    mdl.config.label2id = getattr(mdl.config, \"label2id\", LABEL2ID) or LABEL2ID\n",
        "\n",
        "    orig_forward = mdl.forward\n",
        "    def forward(*args, **kwargs):\n",
        "        kwargs[\"return_dict\"] = True\n",
        "        out = orig_forward(*args, **kwargs)\n",
        "        if isinstance(out, tuple):\n",
        "            return SequenceClassifierOutput(logits=out[0])\n",
        "        return out\n",
        "    mdl.forward = forward\n",
        "\n",
        "    device = 0 if torch.cuda.is_available() else -1\n",
        "    clf = pipeline(\n",
        "        \"text-classification\",\n",
        "        model=mdl,\n",
        "        tokenizer=tok,\n",
        "        device=device,\n",
        "        framework=\"pt\",\n",
        "        function_to_apply=(\"sigmoid\" if POSTPROC == \"sigmoid\" else \"softmax\"),\n",
        "        return_all_scores=(POSTPROC == \"sigmoid\"),\n",
        "    )\n",
        "    print(f\"[DEBUG] loaded: {dirpath} | id2label={mdl.config.id2label}\")\n",
        "    return clf\n",
        "\n",
        "def load_all_saved_models():\n",
        "    models = {}\n",
        "    for mid, path in SAVE_DIRS.items():\n",
        "        if not _is_local_model_dir(path):\n",
        "            print(f\"[SKIP] {mid}: {path} ì—†ìŒ (config.json ë¯¸ì¡´ì¬)\")\n",
        "            continue\n",
        "        if _ensure_label_maps_saved(path):\n",
        "            print(f\"[FIX] ë¼ë²¨ ë§¤í•‘ ì €ì¥ ì™„ë£Œ â†’ {path}/config.json\")\n",
        "        models[mid] = _build_pipeline_local(path)\n",
        "    if not models:\n",
        "        raise RuntimeError(\"ë¡œì»¬ ì²´í¬í¬ì¸íŠ¸ë¥¼ í•˜ë‚˜ë„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. SAVE_DIRS ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
        "    return models\n",
        "\n",
        "def test_single_model(clf, name, text):\n",
        "    t0 = time.time()\n",
        "    out = clf(text, truncation=True, max_length=MAX_LEN)\n",
        "    dt = time.time() - t0\n",
        "\n",
        "    if POSTPROC == \"softmax\":\n",
        "        res = out[0]  # {'label','score'}\n",
        "    else:\n",
        "        scores = {d[\"label\"]: float(d[\"score\"]) for d in out[0]}\n",
        "        pos = scores.get(\"phishing\", None)\n",
        "        assert pos is not None, f\"'phishing' ì ìˆ˜ ì—†ìŒ: keys={list(scores.keys())}\"\n",
        "        pred = \"phishing\" if pos >= THRESH else \"non_phishing\"\n",
        "        res = {\"label\": pred, \"score\": pos}\n",
        "\n",
        "    print(f\"[{name}] {res['label']} (score={res['score']:.4f})  {dt:.4f}s\")\n",
        "    return res, dt\n",
        "\n",
        "def compare_summary(results, times):\n",
        "    print(\"\\n=== ë¹„êµ ìš”ì•½ ===\")\n",
        "    print(\"1) ë¼ë²¨/ìŠ¤ì½”ì–´\")\n",
        "    for name, r in results.items():\n",
        "        print(f\" - {name:20}: {r['label']} ({r['score']:.4f})\")\n",
        "    print(\"\\n2) ì²˜ë¦¬ì‹œê°„(ì˜¤ë¦„ì°¨ìˆœ)\")\n",
        "    for name, t in sorted(times.items(), key=lambda x: x[1]):\n",
        "        print(f\" - {name:20}: {t:.4f}s\")\n",
        "\n",
        "def main():\n",
        "    print(\"[cwd]\", os.getcwd())\n",
        "    print(\"[ls ]\", os.listdir(\".\"))\n",
        "    for mid, p in SAVE_DIRS.items():\n",
        "        print(f\"[check] {mid} -> {p} : {_is_local_model_dir(p)}\")\n",
        "\n",
        "    models = load_all_saved_models()\n",
        "\n",
        "    samples = [\n",
        "        \"ê³ ê°ë‹˜ ëŒ€ì¶œ í•œë„ ìƒí–¥ë˜ì–´ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤. ëŒ€ì¶œ ì‹¤í–‰ì„ ìœ„í•´ ë³¸ì¸ì¸ì¦ í•„ìš”í•©ë‹ˆë‹¤.\",\n",
        "        \"ì•ˆë…•í•˜ì„¸ìš”, ë‚´ì¼ ì˜¤í›„ 3ì‹œì— ë¯¸íŒ… ê°€ëŠ¥í•˜ì‹ ê°€ìš”?\",\n",
        "    ]\n",
        "\n",
        "    for i, text in enumerate(samples, 1):\n",
        "        print(\"\\n\" + \"-\"*60)\n",
        "        print(f\"ìƒ˜í”Œ {i}: {text}\")\n",
        "        res, tm = {}, {}\n",
        "        for mid, clf in models.items():\n",
        "            r, t = test_single_model(clf, mid, text)\n",
        "            res[mid], tm[mid] = r, t\n",
        "        compare_summary(res, tm)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1vUL2ChFCKX"
      },
      "source": [
        "- ì„¸ ëª¨ë¸ ëª¨ë‘ **non_phishing**ìœ¼ë¡œ ë¶„ë¥˜.\n",
        "- **ìŠ¤ì½”ì–´**: small(0.99) < base(0.992~0.999) < large(0.999)  \n",
        "- **ì²˜ë¦¬ ì‹œê°„**: ì¼ë°˜ì ìœ¼ë¡œ *small < base < large*, ë‹¨ ì¼ë¶€ ìƒ˜í”Œì—ì„œëŠ” Baseê°€ ë” ë¹ ë¥¸ ê²½ìš°ë„ ìˆì—ˆë‹¤.\n",
        "- **ê²°ë¡ **: ëª¨ë¸ í¬ê¸°ê°€ ì»¤ì§ˆìˆ˜ë¡ ìŠ¤ì½”ì–´ê°€ ì˜¬ë¼ê°€ê³  ì²˜ë¦¬ ì‹œê°„ë„ ì¦ê°€í•œë‹¤, ë”°ë¼ì„œ\n",
        "ëª¨ë¸ ì„ íƒ ì‹œ ì ì ˆí•œ ê³ ë ¤ê°€ í•„ìš”í•˜ë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWgW8HvDfCnq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}